<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.0.0" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.0.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/myicon.JPEG?v=6.0.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/myicon.JPEG?v=6.0.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.0.0" color="#222">





  <meta name="keywords" content="Hexo, NexT">




  


  <link rel="alternate" href="/atom.xml" title="Heathcliff's Notes" type="application/atom+xml">






<meta name="description" content="We are all in the gutter, but some of us are looking at the stars.">
<meta property="og:type" content="website">
<meta property="og:title" content="分类">
<meta property="og:url" content="http://heathcliff.me/categories/index.html">
<meta property="og:site_name" content="Heathcliff&#39;s Notes">
<meta property="og:description" content="We are all in the gutter, but some of us are looking at the stars.">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-01-07T11:03:05.399Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="分类">
<meta name="twitter:description" content="We are all in the gutter, but some of us are looking at the stars.">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '6.0.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://heathcliff.me/categories/">





  <title>聚类分析（二）：k-means 算法 | Heathcliff's Notes</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> <div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Heathcliff's Notes</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            

            
              首页
            

          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            

            
              标签
            

          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            

            
              分类
            

          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            

            
              归档
            

          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://heathcliff.me/聚类分析（二）：k-means-算法/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heathcliff">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/myicon.JPEG">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heathcliff's Notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">聚类分析（二）：k-means 算法</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-02-10T20:33:10+08:00">2018-02-10</time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning-algorithms/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习算法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/聚类分析（二）：k-means-算法/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="聚类分析（二）：k-means-算法/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/聚类分析（二）：k-means-算法/" class="leancloud_visitors" data-flag-title="聚类分析（二）：k-means 算法">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<p><em>本篇文章为讲述聚类算法的第二篇文章，其它相关文章请参见 <a href="../clustering-analysis/index.html"><strong>聚类分析系列文章</strong></a></em>。</p>
<h1 id="k-means-聚类算法"><a href="#k-means-聚类算法" class="headerlink" title="k-means 聚类算法"></a>k-means 聚类算法</h1><p>k-means 算法是一种经典的针对数值型样本的聚类算法。如前面的博文 <a href="../%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%B1%82%E6%AC%A1%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"><em>聚类分析（一）：层次聚类算法</em></a> 中所述，k-means 算法是一种基于中心点模型的聚类算法，它所产生的每一个 <code>cluster</code> 都维持一个中心点（为属于该 <code>cluster</code> 的所有样本点的均值，k-means 算法由此得名），每一个样本点被分配给距离其最近的中心点所对应的 <code>cluster</code>。在该算法中，<code>cluster</code> 的数目 $ K $ 需要事先指定。我们可以很清楚地看到，在以上聚类场景中，一个最佳的目标是找到 $ K $ 个中心点以及每个样本点的分配方法，使得每个样本点距其被分配的 <code>cluster</code> 所对应的中心点的平方 Euclidean 距离之和最小。而 k-means 算法正是为实现这个目标所提出。</p>
<h2 id="表示为求解特定的优化问题"><a href="#表示为求解特定的优化问题" class="headerlink" title="表示为求解特定的优化问题"></a>表示为求解特定的优化问题</h2><p>假定数据集为 $ \lbrace {\bf x}_1, {\bf x}_2, …, {\bf x}_N \rbrace $，其包含 $ N $ 个样本点，每个样本点的维度为 $ D $。我们的目的是将该数据集划分为 $ K $ 个 <code>cluster</code>，其中 $ K $ 是一个预先给定的值。假设每个 <code>cluster</code> 的中心点为向量 $ {\bf \mu}_k  \in \Bbb{R}^{d} $，其中 $ k = 1, …, K $。如前面所述，我们的目的是找到中心点 $ \lbrace {\bf \mu}_k \rbrace $，以及每个样本点所属的类别，以使每个样本点距其被分配的 <code>cluster</code> 所对应的中心点的平方 Euclidean 距离之和最小。</p>
<p>为方便用数学符号描述该优化问题，我们以变量 $ r_{nk} \in \lbrace 0, 1 \rbrace $ 来表示样本点 $ {\bf x}_n $ 是否被分配至第 $ k $ 个 <code>cluster</code>，若样本点 $ {\bf x}_n $ 被分配至第 $ k $ 个 <code>cluster</code>，则 $ r_{nk} = 1 $ 且 $ r_{nj} = 0  $ $ (j \neq k) $。由此我们可以写出目标函数</p>
<script type="math/tex; mode=display">J = \sum_{n = 1}^{N} \sum_{k = 1}^{K} r_{nk} \| {\bf x}_n -  {\bf \mu}_k \|^{2}</script><p>它表示的即是每个样本点与其被分配的 <code>cluster</code> 的中心点的平方 Euclidean 距离之和。整个优化问题用数学语言描述即是寻找优化变量 $ \lbrace r_{nk} \rbrace $ 和 $ \lbrace {\bf \mu}_k \rbrace $ 的值，以使得目标函数 $ J $ 最小。</p>
<p>我们可以看到，由于 $ \lbrace r_{nk} \rbrace $ 的定义域是非凸的，因而整个优化问题也是非凸的，从而寻找全局最优解变得十分困难，因此，我们转而寻找能得到局部最优解的算法。</p>
<p>k-means 算法即是一种简单高效的可以解决上述问题的迭代算法。k-means 算法是一种交替优化（alternative optimization）算法，其每一步迭代包括两个步骤，这两个步骤分别对一组变量求优而将另一组变量视为定值。具体地，首先我们为中心点 $ \lbrace {\bf \mu}_k \rbrace $ 选定初始值；然后在第一个迭代步骤中固定 $ \lbrace {\bf \mu}_k \rbrace $ 的值，对目标函数 $ J $ 根据  $ \lbrace r_{nk} \rbrace $ 求最小值；再在第二个迭代步骤中固定 $ \lbrace r_{nk} \rbrace $ 的值，对  $ J $ 根据 $ {\bf \mu}_k $ 求最小值；如此交替迭代，直至目标函数收敛。</p>
<p>考虑迭代过程中的两个优化问题。首先考虑固定 $ {\bf \mu}_k $ 求解 $ r_{nk} $ 的问题，可以看到 $ J $ 是关于 $ r_{nk} $ 的线性函数，因此我们很容易给出一个闭式解：$ J $ 包含 $ N $ 个独立的求和项，因此我们可以对每一个项单独求其最小值，显然，$ r_{nk} $ 的解为</p>
<script type="math/tex; mode=display">r_{nk} = \begin{cases} 1, & \text {if $ k = \rm {arg}  \rm {min}_{j}  \| {\bf x}_n -  {\bf \mu}_j \|^{2} $ } \\ 0, & \text {otherwise} \end{cases}</script><p>从上式可以看出，此步迭代的含义即是将每个样本点分配给距离其最近的中心点所对应的 <code>cluster</code>。</p>
<p>再来考虑固定  $ r_{nk} $ 求解 $ {\bf \mu}_k $ 的问题，目标函数 $ J $ 是关于 $ {\bf \mu}_k $ 的二次函数，因此可以通过将 $ J $ 关于 $ {\bf \mu}_k $ 的导数置为 0 来求解 $ J $ 关于  $ {\bf \mu}_k $ 的最小值：</p>
<script type="math/tex; mode=display">2 \sum_{n = 1}^{N} r_{nk}({\bf x}_n -  {\bf \mu}_k) = 0</script><p>容易求出 $ {\bf \mu}_k $ 的值为</p>
<script type="math/tex; mode=display">{\bf \mu}_k = \frac {\sum_{n} r_{nk} {\bf x}_n} {\sum_{n} r_{nk} }</script><p>该式表明，这一步迭代是将中心点更新为所有被分配至该 <code>cluster</code> 的样本点的均值。</p>
<p>k-means 算法的核心即是以上两个迭代步骤，由于每一步迭代均会减小或保持（不会增长）目标函数 $ J $ 的值，因而该算法最终一定会收敛，但可能会收敛至某个局部最优解而不是全局最优解。</p>
<p>虽然上面已经讲的很清楚了，但在这里我们还是总结一下 k-means 算法的过程：</p>
<ol>
<li>初始化每个 <code>cluster</code> 的中心点。最终的聚类结果受初始化的影响很大，一般采用随机的方式生成中心点，对于比较有特点的数据集可采用一些启发式的方法选取中心点。由于 k-means 算法收敛于局部最优解的特性，在有些情况下我们会选取多组初始值，对其分别运行算法，最终选取目标函数值最小的一组方案作为聚类结果；</li>
<li>将每个样本点分配给距离其最近的中心点所对应的 <code>cluster</code>；</li>
<li>更新每个 <code>cluster</code> 的中心点为被分配给该 <code>cluster</code> 的所有样本点的均值；</li>
<li>交替进行 2～3 步，直至迭代到了最大的步数或者前后两次目标函数的值的差值小于一个阈值为止。</li>
</ol>
<p><a href="http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf" rel="external nofollow noopener noreferrer" target="_blank"> PRML 教材 </a>中给出的 k-means 算法的运行示例非常好，这里拿过来借鉴一下，如下图所示。数据集为经过标准化处理（减去均值、对标准差归一化）后的 Old Faithful 数据集，记录的是黄石国家公园的 Old Faithful 热喷泉喷发的时长与此次喷发距离上次喷发的等待时间。我们选取 $ K = 2 $，小图（a）为对中心点初始化，小图（b）至小图（i）为交替迭代过程，可以看到，经过短短的数次迭代，k-means 算法就已达到了收敛。</p>
<div align="center">
<img src="http://free-cn-01.cdn.bilnn.com/ddimg/jfs/t1/119583/4/518/365049/5e9d20c0Ec32fe6fa/65c3e61f56e00df9.png" width="660" height="550" alt="k-means 算法运行图示" align="center">
</div>


<h2 id="算法复杂度及其优缺点"><a href="#算法复杂度及其优缺点" class="headerlink" title="算法复杂度及其优缺点"></a>算法复杂度及其优缺点</h2><h3 id="算法复杂度"><a href="#算法复杂度" class="headerlink" title="算法复杂度"></a>算法复杂度</h3><p>k-means 算法每次迭代均需要计算每个样本点到每个中心点的距离，一共要计算 $ O(NK) $ 次，而计算某一个样本点到某一个中心点的距离所需时间复杂度为 $  O(D) $，其中 $ N $ 为样本点的个数，$ K $ 为指定的聚类个数，$ D $ 为样本点的维度；因此，一次迭代过程的时间复杂度为 $ O(NKD) $，又由于迭代次数有限，所以 k-means 算法的时间复杂度为 $ O(NKD) $。</p>
<p>实际实现中，一般采用高效的数据结构（如 kd 树）来结构化地存储对象之间的距离信息，因而可减小 k-means 算法运行的时间开销。</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>k-means 算法虽简单易用，但其有一些很明显的缺点，总结如下：</p>
<ul>
<li>由于其假设每个 <code>cluster</code> 的先验概率是一样的，这样就容易产生出大小（指包含的样本点的多少）相对均匀的 <code>cluster</code>；但事实上的数据的 <code>cluster</code> 有可能并不是如此。</li>
<li>由于其假设每一个 <code>cluster</code> 的分布形状都为球形（spherical），（“球形分布”表明一个 <code>cluster</code> 内的数据在每个维度上的方差都相同，且不同维度上的特征都不相关），这样其产生的聚类结果也趋向于球形的 <code>cluster</code> ，对于具有非凸的或者形状很特别的 <code>cluster</code> 的数据集，其聚类效果往往很差。</li>
<li>由于其假设不同的 <code>cluster</code> 具有相似的密度，因此对于具有密度差别较大的 <code>cluster</code> 的数据集，其聚类效果不好。</li>
<li>其对异常点（outliers）很敏感，这是由于其采用了平方 Euclidean 距离作为距离衡量准则。</li>
<li><code>cluster</code> 的数目 $ K $ 需要预先指定，但由于很多情况下我们对数据也是知之甚少的，因而怎么选择一个合适的 $ K $ 值也是一个问题。一般确定 $ K $ 的值的方法有以下几种：a）选定一个 $ K $ 的区间，例如 2～10，对每一个 $ K $ 值分别运行多次 k-means 算法，取目标函数 $ J $ 的值最小的 $ K $ 作为聚类数目；b）利用 <a href="https://www.wikipedia.com/en/Determining_the_number_of_clusters_in_a_data_set" rel="external nofollow noopener noreferrer" target="_blank"> Elbow 方法 </a> 来确定 $ K $ 的值；c）利用 <a href="https://datasciencelab.wordpress.com/tag/gap-statistic/" rel="external nofollow noopener noreferrer" target="_blank"> gap statistics </a> 来确定 $ K $ 的值；d）根据问题的目的和对数据的粗略了解来确定 $ K $ 的值。</li>
<li>其对初始值敏感，不好的初始值往往会导致效果不好的聚类结果（收敛到不好的局部最优解）。一般采取选取多组初始值的方法或采用优化初始值选取的算法（如 <a href="http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf" rel="external nofollow noopener noreferrer" target="_blank"> k-means++ 算法 </a>）来克服此问题。</li>
<li>其仅适用于数值类型的样本。但其扩展算法 <a href="http://www.irma-international.org/viewtitle/10828/" rel="external nofollow noopener noreferrer" target="_blank"> k-modes 算法 </a>（专门针对离散型数据所设计） 和 k-medoid 算法（中心点只能在样本数据集中取得） 适用于离散类型的样本。</li>
</ul>
<p>其中前面三个缺点都是基于 k-means 算法的假设，这些假设的来源是 k-means 算法仅仅用一个中心点来代表 <code>cluster</code>，而关于 <code>cluster</code> 的其他信息一概没有做限制，那么根据 <a href="https://www.wikipedia.com/en/Occam&#39;s_razor" rel="external nofollow noopener noreferrer" target="_blank"> Occam 剃刀原理 </a>，k-means 算法中的 <code>cluster</code> 应是最简单的那一种，即对应这三个假设。在博文 <a href="../%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B%E4%B8%8EEM%E7%AE%97%E6%B3%95/"><em>聚类分析（三）：高斯混合模型与 EM 算法</em></a> 中，我们讲到 k-means 算法是 “EM 算法求解高斯混合模型的最大似然参数估计问题” 的特例的时候，会更正式地得出这些假设的由来。</p>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>尽管 k-means 算法有以上这些缺点，但一些好的地方还是让其应用广泛，其优点总结如下：</p>
<ul>
<li>实现起来简单，总是可以收敛，算法复杂度低。</li>
<li>其产生的聚类结果容易阐释。</li>
<li>在实际应用中，数据集如果不满足以上部分假设条件，仍然有可能产生比较让人满意的聚类结果。</li>
</ul>
<hr>
<h1 id="实现-k-means-聚类"><a href="#实现-k-means-聚类" class="headerlink" title="实现 k-means 聚类"></a>实现 k-means 聚类</h1><p>在这一部分，我们首先手写一个简单的 k-means 算法，然后用该算法来展示一下不同的初始化值对聚类结果的影响；然后再使用 scikit-learn 中的 <code>KMeans</code> 类来展示 k-means 算法对不同类型的数据集的聚类效果。</p>
<h2 id="利用-python-实现-k-means-聚类"><a href="#利用-python-实现-k-means-聚类" class="headerlink" title="利用 python 实现 k-means 聚类"></a>利用 python 实现 k-means 聚类</h2><p>首先我们手写一个 k-means 聚类算法，这里，我将该算法封装成了一个类，代码如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> copy</div><div class="line"><span class="keyword">import</span> time</div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">KMeansClust</span><span class="params">()</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_clust=<span class="number">2</span>, max_iter=<span class="number">50</span>, tol=<span class="number">1e-10</span>)</span>:</span></div><div class="line">        self.data_set = <span class="keyword">None</span></div><div class="line">        self.centers_his = []</div><div class="line">        self.pred_label = <span class="keyword">None</span></div><div class="line">        self.pred_label_his = []</div><div class="line">        self.n_clust = n_clust</div><div class="line">        self.max_iter = max_iter</div><div class="line">        self.tol = tol</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, data_set)</span>:</span></div><div class="line">        self.data_set = data_set</div><div class="line">        n_samples, n_features = self.data_set.shape</div><div class="line">        self.pred_label = np.zeros(n_samples, dtype=int)</div><div class="line"> </div><div class="line">    start_time = time.time()</div><div class="line"> </div><div class="line">        <span class="comment"># 初始化中心点</span></div><div class="line">        centers = np.random.rand(self.n_clust, n_features)</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n_features):</div><div class="line">            dim_min = np.min(self.data_set[:, i])</div><div class="line">            dim_max = np.max(self.data_set[:, i])</div><div class="line">            centers[:, i] = dim_min + (dim_max - dim_min) * centers[:, i]</div><div class="line">        self.centers_his.append(copy.deepcopy(centers))</div><div class="line">        self.pred_label_his.append(copy.deepcopy(self.pred_label))</div><div class="line"></div><div class="line">        print(<span class="string">"The initializing cluster centers are: %s"</span> % centers)</div><div class="line"></div><div class="line">        <span class="comment"># 开始迭代</span></div><div class="line">        pre_J = <span class="number">1e10</span></div><div class="line">        iter_cnt = <span class="number">0</span></div><div class="line">        <span class="keyword">while</span> iter_cnt &lt; self.max_iter:</div><div class="line">            iter_cnt += <span class="number">1</span></div><div class="line">            <span class="comment"># E 步：将各个样本点分配给距其最近的中心点所对应的 cluster</span></div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(n_samples):</div><div class="line">                self.pred_label[i] = np.argmin(np.sum((self.data_set[i, :] - centers) ** <span class="number">2</span>, axis=<span class="number">1</span>))</div><div class="line">            <span class="comment"># M 步：更新中心点</span></div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n_clust):</div><div class="line">                centers[i] = np.mean(self.data_set[self.pred_label == i], axis=<span class="number">0</span>)</div><div class="line">            self.centers_his.append(copy.deepcopy(centers))</div><div class="line">            self.pred_label_his.append(copy.deepcopy(self.pred_label))</div><div class="line">            <span class="comment"># 重新计算目标函数 J</span></div><div class="line">            crt_J = np.sum((self.data_set - centers[self.pred_label]) ** <span class="number">2</span>) / n_samples</div><div class="line">            print(<span class="string">"iteration %s, current value of J: %.4f"</span> % (iter_cnt, crt_J))</div><div class="line">            <span class="comment"># 若前后两次迭代产生的目标函数的值变化不大，则结束迭代</span></div><div class="line">            <span class="keyword">if</span> np.abs(pre_J - crt_J) &lt; self.tol:</div><div class="line">                <span class="keyword">break</span></div><div class="line">            pre_J = crt_J</div><div class="line"></div><div class="line">        print(<span class="string">"total iteration num: %s, final value of J: %.4f, time used: %.4f seconds"</span> </div><div class="line">                % (iter_cnt, crt_J, time.time() - start_time))</div><div class="line"></div><div class="line">    <span class="comment"># 可视化算法每次迭代产生的结果</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plot_clustering</span><span class="params">(self, iter_cnt=<span class="number">-1</span>, title=None)</span>:</span></div><div class="line">        <span class="keyword">if</span> iter_cnt &gt;= len(self.centers_his) <span class="keyword">or</span> iter_cnt &lt; <span class="number">-1</span>:</div><div class="line">            <span class="keyword">raise</span> Exception(<span class="string">"iter_cnt is not valid!"</span>)</div><div class="line">        plt.scatter(self.data_set[:, <span class="number">0</span>], self.data_set[:, <span class="number">1</span>],</div><div class="line">                        c=self.pred_label_his[iter_cnt], alpha=<span class="number">0.8</span>)</div><div class="line">        plt.scatter(self.centers_his[iter_cnt][:, <span class="number">0</span>], self.centers_his[iter_cnt][:, <span class="number">1</span>],</div><div class="line">                        c=<span class="string">'r'</span>, marker=<span class="string">'x'</span>)</div><div class="line">        <span class="keyword">if</span> title <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">            plt.title(title, size=<span class="number">14</span>)</div><div class="line">        plt.axis(<span class="string">'on'</span>)</div><div class="line">        plt.tight_layout()</div></pre></td></tr></table></figure></p>
<p>创建一个 <code>KMeansClust</code> 类的实例即可进行 k-means 聚类，在创建实例的时候，会初始化一系列的参数，如聚类个数、最大迭代次数、终止迭代的条件等等；然后该实例调用自己的方法 <code>predict</code> 即可对给定的数据集进行 k-means 聚类；方法 <code>plot_clustering</code> 则可以可视化每一次迭代所产生的结果。利用 <code>KMeansClust</code> 类进行 k-means 聚类的代码如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    <span class="comment"># 生成数据集</span></div><div class="line">    n_samples = <span class="number">1500</span></div><div class="line">    centers = [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">8</span>, <span class="number">3.5</span>]]</div><div class="line">    cluster_std = [<span class="number">2</span>, <span class="number">1.0</span>, <span class="number">0.5</span>]</div><div class="line">    X, y = make_blobs(n_samples=n_samples, centers=centers, cluster_std=cluster_std)</div><div class="line"></div><div class="line">    <span class="comment"># 运行 k-means 算法</span></div><div class="line">    kmeans_cluster = KMeansClust(n_clust=<span class="number">3</span>)</div><div class="line">    kmeans_cluster.predict(X)</div><div class="line"></div><div class="line">    <span class="comment"># 可视化中心点的初始化以及算法的聚类结果</span></div><div class="line">    plt.subplots(<span class="number">1</span>, <span class="number">2</span>)</div><div class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</div><div class="line">    kmeans_cluster.plot_clustering(iter_cnt=<span class="number">0</span>, title=<span class="string">'initialization centers'</span>)</div><div class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</div><div class="line">    kmeans_cluster.plot_clustering(iter_cnt=<span class="number">-1</span>, title=<span class="string">'k-means clustering result'</span>)</div><div class="line">    plt.show()</div></pre></td></tr></table></figure></p>
<p>以上代码首先由三个不同的球形高斯分布产生了一个数据集，而后运行了 k-means 聚类方法，中心点的初始化是随机生成的。最终得到如下的输出和可视化结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">The initializing cluster centers are: </div><div class="line">[[-6.12152378  2.14971475]</div><div class="line"> [ 6.71575768 -5.41421872]</div><div class="line"> [-1.30016464 -2.3824513 ]]</div><div class="line">iteration 1, current value of J: 12.5459</div><div class="line">iteration 2, current value of J: 7.3479</div><div class="line">iteration 3, current value of J: 5.2928</div><div class="line">iteration 4, current value of J: 5.1493</div><div class="line">iteration 5, current value of J: 5.1152</div><div class="line">iteration 6, current value of J: 5.1079</div><div class="line">iteration 7, current value of J: 5.1065</div><div class="line">iteration 8, current value of J: 5.1063</div><div class="line">iteration 9, current value of J: 5.1052</div><div class="line">iteration 10, current value of J: 5.0970</div><div class="line">iteration 11, current value of J: 5.0592</div><div class="line">iteration 12, current value of J: 4.9402</div><div class="line">iteration 13, current value of J: 4.5036</div><div class="line">iteration 14, current value of J: 3.6246</div><div class="line">iteration 15, current value of J: 3.2003</div><div class="line">iteration 16, current value of J: 3.1678</div><div class="line">iteration 17, current value of J: 3.1658</div><div class="line">iteration 18, current value of J: 3.1657</div><div class="line">iteration 19, current value of J: 3.1657</div><div class="line">total iteration num: 19, final value of J: 3.1657, time used: 0.3488 seconds</div></pre></td></tr></table></figure></p>
<div align="center">
<img src="http://free-cn-01.cdn.bilnn.com/ddimg/jfs/t1/117435/1/1968/666134/5e9d2107Eb6f19bba/2a9ff64f580f44c1.png" width="1000" height="450" alt="k-means 算法运行结果（好的初始化）" align="center">
</div>


<p>可以看到，这次算法产生的聚类结果比较好；但并不总是这样，例如某次运行该算法产生的聚类结果如下图所示，可以看出，这一次由于初始值的不同，该算法收敛到了一个不好的局部最优解。</p>
<div align="center">
<img src="http://free-cn-01.cdn.bilnn.com/ddimg/jfs/t1/99647/29/19371/745631/5e9d2106E95772b3c/2067e237eb062d8a.png" width="1000" height="450" alt="k-means 算法运行结果（不好的初始化）" align="center">
</div>


<h2 id="利用-sklearn-实现-k-means-聚类"><a href="#利用-sklearn-实现-k-means-聚类" class="headerlink" title="利用 sklearn 实现 k-means 聚类"></a>利用 sklearn 实现 k-means 聚类</h2><p>sklearn 中的 <code>KMeans</code> 类可以用来进行 k-means 聚类，sklearn 对该模块进行了计算的优化以及中心点初始化的优化，因而其效果和效率肯定要比上面手写的 k-means 算法要好。在这里，我们直接采用 sklearn 官网的 <a href="http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_assumptions.html#sphx-glr-auto-examples-cluster-plot-kmeans-assumptions-py" rel="external nofollow noopener noreferrer" target="_blank">demo</a> 来展示 <code>KMeans</code> 类的用法，顺便看一下 k-means 算法在破坏了其假设条件的数据集下的运行结果。代码如下（直接照搬 sklearn 官网）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</div><div class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</div><div class="line"></div><div class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">12</span>))</div><div class="line"></div><div class="line">n_samples = <span class="number">1500</span></div><div class="line">random_state = <span class="number">170</span></div><div class="line">X, y = make_blobs(n_samples=n_samples, random_state=random_state)</div><div class="line"></div><div class="line"><span class="comment"># 设定一个不合理的 K 值</span></div><div class="line">y_pred = KMeans(n_clusters=<span class="number">2</span>, random_state=random_state).fit_predict(X)</div><div class="line"></div><div class="line">plt.subplot(<span class="number">221</span>)</div><div class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y_pred)</div><div class="line">plt.title(<span class="string">"Incorrect Number of Blobs"</span>)</div><div class="line"></div><div class="line"><span class="comment"># 产生一个非球形分布的数据集</span></div><div class="line">transformation = [[<span class="number">0.60834549</span>, <span class="number">-0.63667341</span>], [<span class="number">-0.40887718</span>, <span class="number">0.85253229</span>]]</div><div class="line">X_aniso = np.dot(X, transformation)</div><div class="line">y_pred = KMeans(n_clusters=<span class="number">3</span>, random_state=random_state).fit_predict(X_aniso)</div><div class="line"></div><div class="line">plt.subplot(<span class="number">222</span>)</div><div class="line">plt.scatter(X_aniso[:, <span class="number">0</span>], X_aniso[:, <span class="number">1</span>], c=y_pred)</div><div class="line">plt.title(<span class="string">"Anisotropicly Distributed Blobs"</span>)</div><div class="line"></div><div class="line"><span class="comment"># 产生一个各 cluster 的密度不一致的数据集</span></div><div class="line">X_varied, y_varied = make_blobs(n_samples=n_samples,</div><div class="line">                                cluster_std=[<span class="number">1.0</span>, <span class="number">2.5</span>, <span class="number">0.5</span>],</div><div class="line">                                random_state=random_state)</div><div class="line">y_pred = KMeans(n_clusters=<span class="number">3</span>, random_state=random_state).fit_predict(X_varied)</div><div class="line"></div><div class="line">plt.subplot(<span class="number">223</span>)</div><div class="line">plt.scatter(X_varied[:, <span class="number">0</span>], X_varied[:, <span class="number">1</span>], c=y_pred)</div><div class="line">plt.title(<span class="string">"Unequal Variance"</span>)</div><div class="line"></div><div class="line"><span class="comment"># 产生一个各 cluster 的样本数目不一致的数据集</span></div><div class="line">X_filtered = np.vstack((X[y == <span class="number">0</span>][:<span class="number">500</span>], X[y == <span class="number">1</span>][:<span class="number">100</span>], X[y == <span class="number">2</span>][:<span class="number">50</span>]))</div><div class="line">y_pred = KMeans(n_clusters=<span class="number">3</span>,</div><div class="line">                random_state=random_state).fit_predict(X_filtered)</div><div class="line"></div><div class="line">plt.subplot(<span class="number">224</span>)</div><div class="line">plt.scatter(X_filtered[:, <span class="number">0</span>], X_filtered[:, <span class="number">1</span>], c=y_pred)</div><div class="line">plt.title(<span class="string">"Unevenly Sized Blobs"</span>)</div><div class="line"></div><div class="line">plt.show()</div></pre></td></tr></table></figure></p>
<p>运行结果如下图所示：</p>
<div align="center">
<img src="http://free-cn-01.cdn.bilnn.com/ddimg/jfs/t1/110025/24/13130/303358/5e9d219cE0ecb25f2/9254089d64989e5b.png" width="780" height="650" alt="k-means 算法在不同数据集下的表现" align="center">
</div>


<p>上述代码分别产生了四个数据集，并分别对它们进行 k-means 聚类。第一个数据集符合所有 k-means 算法的假设条件，但是我们给定的 $ K $ 值与实际数据不符；第二个数据集破坏了球形分布的假设条件；第三个数据集破坏了各 <code>cluster</code> 的密度相近的假设条件；第四个数据集则破坏了各 <code>cluster</code> 内的样本数目相近的假设条件。可以看到，虽然有一些数据集破坏了 k-means 算法的某些假设条件（密度相近、数目相近），但算法的聚类结果仍然比较好；但如果数据集的分布偏离球形分布太远的话，最终的聚类结果会很差。</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/聚类/" rel="tag"># 聚类</a>
          
            <a href="/tags/非监督学习/" rel="tag"># 非监督学习</a>
          
            <a href="/tags/k-means-算法/" rel="tag"># k-means 算法</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/聚类分析（一）：层次聚类算法/" rel="next" title="聚类分析（一）：层次聚类算法">
                <i class="fa fa-chevron-left"></i> 聚类分析（一）：层次聚类算法
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/聚类分析（三）：高斯混合模型与EM算法/" rel="prev" title="聚类分析（三）：高斯混合模型与 EM 算法">
                聚类分析（三）：高斯混合模型与 EM 算法 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript" rel="external nofollow noopener noreferrer" target="_blank">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/myicon.JPEG" alt="Heathcliff">
            
              <p class="site-author-name" itemprop="name">Heathcliff</p>
              <p class="site-description motion-element" itemprop="description">We are all in the gutter, but some of us are looking at the stars.</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">9</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    <span class="site-state-item-count">3</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    <span class="site-state-item-count">28</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#k-means-聚类算法"><span class="nav-number">1.</span> <span class="nav-text">k-means 聚类算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#表示为求解特定的优化问题"><span class="nav-number">1.1.</span> <span class="nav-text">表示为求解特定的优化问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#算法复杂度及其优缺点"><span class="nav-number">1.2.</span> <span class="nav-text">算法复杂度及其优缺点</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#算法复杂度"><span class="nav-number">1.2.1.</span> <span class="nav-text">算法复杂度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缺点"><span class="nav-number">1.2.2.</span> <span class="nav-text">缺点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#优点"><span class="nav-number">1.2.3.</span> <span class="nav-text">优点</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#实现-k-means-聚类"><span class="nav-number">2.</span> <span class="nav-text">实现 k-means 聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#利用-python-实现-k-means-聚类"><span class="nav-number">2.1.</span> <span class="nav-text">利用 python 实现 k-means 聚类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#利用-sklearn-实现-k-means-聚类"><span class="nav-number">2.2.</span> <span class="nav-text">利用 sklearn 实现 k-means 聚类</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Heathcliff</span>

  

  
</div>









<span id="busuanzi_container_site_pv">
    本站总访问量 <span id="busuanzi_value_site_pv"></span> 次
</span>

        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.0.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.0.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.0.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.0.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.0.0"></script>



  


  

    
      <script id="dsq-count-scr" src="https://heathcliff.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://heathcliff.me/聚类分析（二）：k-means-算法/';
          this.page.identifier = '聚类分析（二）：k-means-算法/';
          this.page.title = '聚类分析（二）：k-means 算法';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://heathcliff.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("s2RkSDxfHn2dwq6oHcIhF6UI-gzGzoHsz", "MhK9geETXDua79cxpft6W6ne");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

  
</body>
</html>
