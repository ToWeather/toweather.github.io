<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[聚类分析（一）：层次聚类算法]]></title>
    <url>%2F%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%B1%82%E6%AC%A1%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[聚类算法综述聚类分析（clustering analysis）是将一组对象根据其特征分成不同的 cluster，使得同一 cluster 内的对象在某种意义上比不同的 cluster 之间的对象更为相似。由于 “cluster“ 没有一个明确的定义，因而会有基于不同的模型的聚类算法，其中被广泛运用的聚类算法有以下几类： 基于连通模型（connectivity-based）的聚类算法： 即本文将要讲述的层次聚类算法，其核心思想是按照对象之间的距离来聚类，两个离的近的对象要比两个离的远的对象更有可能属于同一 cluster。 基于中心点模型（centroid-based）的聚类算法： 在此类算法中，每个 cluster 都维持一个中心点（centorid），该中心点不一定属于给定的数据集。当预先指定聚类数目 k 时，此类算法需要解决一个优化问题，目标函数为所有的对象距其所属的 cluster 的中心点的距离的平方和，优化变量为每个 cluster 的中心点以及每个对象属于哪个 cluster；此优化问题被证明是 NP-hard 的，但有一些迭代算法可以找到近似解，k-means 算法即是其中的一种。 基于分布模型（distribution-based）的聚类算法： 此类算法认为数据集的中数据是由一种混合概率模型所采样得到的，因而只要将可能属于同一概率分布所产生的数据归为同一 cluster 即可。 基于密度（density-based）的聚类算法： 在此类算法中，密度高的区域被归为一个 cluster，cluster 之间由密度低的区域隔开，密度低的区域中的点被认为是噪声 （noise），常用的密度聚类算法为 DBSCAN 和 OPTICS。 层次聚类综述层次聚类算法 (hierarchical clustering) 将数据集划分为一层一层的 clusters，后面一层生成的 clusters 基于前面一层的结果。层次聚类算法一般分为两类： Agglomerative 层次聚类：又称自底向上（bottom-up）的层次聚类，每一个对象最开始都是一个 cluster，每次按一定的准则将最相近的两个 cluster 合并生成一个新的 cluster，如此往复，直至最终所有的对象都属于一个 cluster。本文主要关注此类算法。 Divisive 层次聚类： 又称自顶向下（top-down）的层次聚类，最开始所有的对象均属于一个 cluster，每次按一定的准则将某个 cluster 划分为多个 cluster，如此往复，直至每个对象均是一个 cluster。 下图直观的给出了层次聚类的思想以及以上两种聚类策略的异同。 另外，需指出的是，层次聚类算法是一种贪心算法（greedy algorithm），因其每一次合并或划分都是基于某种局部最优的选择。 树形图树形图（dendrogram）可以直观地表示层次聚类的成果。一个有 5 个点的树形图如下图所示，其中纵坐标高度表示不同的 cluster 之间的距离（“距离”的衡量准则可以多种多样，详见本文后面的定义），可以从这张图看到，\( x_1 \) 和 \( x_2 \) 的距离最近（为 1），因此将 \( x_1 \) 和 \( x_2 \) 合并为一个 cluster \( (x_1, x_2) \)，所以在树形图中首先将节点 \( x_1 \) 和 \( x_2 \) 连接，使其成为一个新的节点 \( (x_1, x_2) \) 的子节点，并将这个新的节点的高度置为 1；之后再在剩下的 4 个 cluster \( (x_1, x_2) \)， \( x_3 \)， \( x_4 \) 和 \( x_5 \) 中选取距离最近的两个 cluster 合并，\( x_4 \) 和 \( x_5 \) 的距离最近（为 2），因此将 \( x_4 \) 和 \( x_5 \) 合并为一个 cluster \( (x_4, x_5) \)，体现在树形图上，是将节点 \( x_4 \) 和 \( x_5 \) 连接，使其成为一个新的节点 \( (x_4, x_5) \) 的子节点，并将此新节点的高度置为 2；….依次模式进行树形图的生成，直至最终只剩下一个 cluster \( ((x_1, x_2), x_3), (x_4, x_5)) \)。可以直观地看到，如果我们想得到一个聚类结果，使任意的两个 cluster 之间的距离都不大于 \( h \)，我们只要在树形图上作一条水平的直线对其进行切割，使其纵坐标等于 \( h \)，即可获得对应的聚类结果。例如，在下面的树形图中，设 \( h=2.5 \)，即可得到 3 个 cluster \( (x_1, x_2) \)， \( x_3 \) 和 \( (x_4, x_5) \)。 对象之间的距离衡量cluster 之间的距离衡量 Agglomerative 层次聚类算法Lance-William 方法Naive 算法]]></content>
      <categories>
        <category>机器学习算法</category>
      </categories>
      <tags>
        <tag>聚类</tag>
        <tag>非监督学习</tag>
        <tag>层次聚类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 中的 Unicode String 和 Byte String]]></title>
    <url>%2FPython-%E4%B8%AD%E7%9A%84-Unicode-string-%E5%92%8C-Byte-string%2F</url>
    <content type="text"><![CDATA[python 2.x 和 python 3.x 字符串类型的区别python 2.x 中字符编码的坑是历史遗留问题，到 python 3.x 已经得到了很好的解决，在这里简要梳理一下二者处理字符串的思路。 python 2.x str 类型：处理 binary 数据和 ASCII 文本数据。 unicode 类型：处理非 ASCII 文本数据。 python 3.x bytes 类型：处理 binary 数据，同 str 类型一样是一个序列类型，其中每个元素均为一个 byte（本质上是一个取值为 0~255 的整型对象），用于处理二进制文件或数据（如图像，音频等）。 str 类型：处理 unicode 文本数据（包含 ASCII 文本数据）。 bytearray 类型：bytes 类型的变种，但是此类型是 mutable 的。 Unicode 简介包括 ASCII 码、latin-1 编码 和 utf-8 编码 等在内的码都被认为是 unicode 码。 编码和解码的概念 编码（encoding）：将字符串映射为一串原始的字节。 解码（decoding）：将一串原始的字节翻译成字符串。 ASCII码 编码长度为 1 个 byte. 编码范围为 0x00~0x7F，只包含一些常见的字符。 latin-1码 编码长度为 1 个 byte. 编码范围为 0x00~0xFF，能支持更多的字符（如 accent character），兼容 ASCII 码。 utf-8码 编码长度可变，为 1~4 个 byte。 当编码长度为 1 个 byte 时，等同于 ASCII 码，取值为 0x00 ~ 0x7F；当编码长度大于 1 个 byte 时，每个 byte 的取值为 0x80 ~ 0xFF。 其它编码 utf-16，编码长度为定长 2 个 byte。 utf-32，编码长度为定长 4 个 byte。 Unicode 字符串的存储方式在内存中的存储方式unicode 字符串在内存中以一种与编码方式无关的方式存储：unicode code point，在表示 unicode 字符串时可以以 unicode code point 的方式表示，例如在下面的例子 中，a 和 b 表示的是同一字符串（其中 &#39;\uNNNN&#39; 即为 unicode code point，N 为一个十六进制位；当 unicode code point 的取值在 0~255 范围内时，也可以 &#39;\xNN&#39; 的形式表示）：1234567# python 2.7&gt;&gt;&gt; a = u'\u5a1c\u5854\u838e'&gt;&gt;&gt; b = u'娜塔莎'&gt;&gt;&gt; print a, b娜塔莎 娜塔莎&gt;&gt;&gt; c = u'\xe4'ä 在文件等外部媒介中的存储方式unicode 字符串在文件等外部媒介中须按照指定的编码方式将字符串转换为原始字节串存储。 字符表示python 3.x在 python 3.x 中，str 类型即可满足日常的字符需求（不论是 ASCII 字符还是国际字符），如下例所示：123456# python 3.6&gt;&gt;&gt; a = 'Natasha, 娜塔莎'&gt;&gt;&gt; type(a)str&gt;&gt;&gt; len(a)12 可以看到，python 3.x 中得到的 a 的长度为 12（包含空格），没有任何问题；我们可以对 a 进行编码，将其转换为 bytes 类型：123456# python 3.6&gt;&gt;&gt; b = a.encode('utf-8')&gt;&gt;&gt; bb'Natasha, \xe5\xa8\x9c\xe5\xa1\x94\xe8\x8e\x8e'&gt;&gt;&gt; type(b)bytes 从上面可以看出，bytes 类型的对象中的某个字节的取值在 0x00 ~ 0x7F 时，控制台的输出会显示出其对应的 ASCII 码字符，但其本质上是一个原始字节，不应与任何字符等同。同理，我们也可以将一个 bytes 类型的对象译码为一个 str 类型的对象：1234# python 3.6&gt;&gt;&gt; a = b.decode('utf-8')&gt;&gt;&gt; a'Natasha, 娜塔莎' python 2.x在 python 2.x 中，如果还是用 str 类型来表示国际字符，就会有问题：12345678910# python 2.7&gt;&gt;&gt; a = 'Natasha, 娜塔莎'&gt;&gt;&gt; type(a)str&gt;&gt;&gt; a'Natasha, \xe5\xa8\x9c\xe5\xa1\x94\xe8\x8e\x8e'&gt;&gt;&gt; len(a)18&gt;&gt;&gt; print aNatasha, 娜塔莎 可以看到，python 2.x 中虽然定义了一个 ASCII 字符和中文字符混合的 str 字符串，但实际上 a 在内存中存储为一串字节序列，且长度也是该字节序列的长度，很明显与我们的定义字符串的初衷不符合。值得注意的是，这里 a 正好是字符串 &#39;Natasha, 娜塔莎&#39; 的 utf-8 编码的结果，且将 a 打印出来的结果和我们的定义初衷相符合，这其实与控制台的默认编码方式有关，这里控制台的默认编码方式正好是 utf-8，获取控制台的默认编码方式的方式如下:123456# python 2.7&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.stdin.encoding # 控制台的输入编码，可解释前例中 a 在内存中的表现形式'utf-8'&gt;&gt;&gt; sys.stdout.encoding # 控制台的输出编码，可解释前例中打印 a 的显示结果'utf-8' 另外，sys.getdefaultencoding()函数也会得到一种编码方式，得到的结果是系统的默认编码方式，在 python 2.x 中，该函数总是返回 &#39;ascii&#39;, 这表明在对字符串编译码时不指定编码方式时所采用的编码方式为ASCII 编码；除此之外，在 python 2.x 中，ASCII 编码方式还会被用作隐式转换，例如 json.dumps() 函数在默认情况下总是返回一串字节串，不论输入的数据结构里面的字符串是 unicode 类型还是 str 类型。在 python 3.x 中，隐式转换已经被禁止（也可以说，python 3.x 用不到隐式转换：&gt;）。切回正题，在 python 2.x 表示国际字符的正确方式应该是定义一个 unicode 类型字符串，如下所示：1234567891011121314# python 2.7&gt;&gt;&gt; a = u'Natasha, 娜塔莎'&gt;&gt;&gt; type(a)unicode&gt;&gt;&gt; len(a)12&gt;&gt;&gt; b = a.encode('utf-8')&gt;&gt;&gt; b'Natasha, \xe5\xa8\x9c\xe5\xa1\x94\xe8\x8e\x8e'&gt;&gt;&gt; type(b)str&gt;&gt;&gt; a = b.decode('utf-8')&gt;&gt;&gt; au'Natasha, \u5a1c\u5854\u838e' 另外，我们可以对 unicode 类型字符串进行编码操作，对 str 类型字符串进行译码操作。 文本文件操作python 3.x在 python 3.x 中，文本文件的读写过程中的编解码过程可以通过指定 open 函数的参数 encoding 的值来自动进行（python 3.x 中的默认情况下文件的编码方式可以由函数 sys.getfilesystemencoding()得到，如：12345678910111213# python 3.6&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.getfilesystemencoding()'utf-8'&gt;&gt;&gt; a = '娜塔莎'&gt;&gt;&gt; f = open('data.txt', 'w', encoding='utf-8')&gt;&gt;&gt; f.write(a)3&gt;&gt;&gt; f.close()&gt;&gt;&gt; f = open('data.txt', 'w', encoding='utf-8')&gt;&gt;&gt; f.read()'娜塔莎'&gt;&gt;&gt; f.close() 当然，也可以先手动将字符串编码为字节串，然后再以二进制模式的方式写入文件，再以二进制模式的方式读取文件，最后再手动将读取出来的数据解码为字符串，如：12345678910# python 3.6&gt;&gt;&gt; a = '娜塔莎'&gt;&gt;&gt; b = a.encode('utf-8')&gt;&gt;&gt; f = open('data.txt', 'wb')&gt;&gt;&gt; f.write(b)9&gt;&gt;&gt; f.close()&gt;&gt;&gt; f.read().decode('utf-8')'娜塔莎'&gt;&gt;&gt; f.close() python 2.x在 python 2.x 中，open 函数只支持读写二进制文件或者文件中的字符大小为 1 个 Byte 的文件，写入的数据为字节，读取出来的数据类型为 str；codecs.open 函数则支持自动读写 unicode 文本文件，如：12345678910# python 2.7&gt;&gt;&gt; import codecs&gt;&gt;&gt; a = u'安德烈'&gt;&gt;&gt; f = codecs.open('data.txt', 'w', encoding='utf-8')&gt;&gt;&gt; f.write(a)&gt;&gt;&gt; f.close()&gt;&gt;&gt; f = codecs.open('data.txt', 'r', encoding='utf-8') &gt;&gt;&gt; print f.read()安德烈&gt;&gt;&gt; f.close() 类似地，也可以先手动将字符串编码为字节串，然后再以二进制模式的方式写入文件，再以二进制模式的方式读取文件，最后再手动将读取出来的数据解码为字符串，如：123456789# python 2.7&gt;&gt;&gt; b = a.encode('utf-8')&gt;&gt;&gt; f = open('data.txt', 'w')&gt;&gt;&gt; f.write(b)&gt;&gt;&gt; f.close()&gt;&gt;&gt; f = open('data.txt', 'r')&gt;&gt;&gt; print f.read().decode('utf-8')安德烈&gt;&gt;&gt; f.close() 总之，在 python 2.x 中读写文件注意两点，一是从文件读取到数据之后的第一件事就是将其按照合适的编码方式译码，二是当所有操作完成需要写入文件时，一定要将要写入的字符串按照合适的编码方式编码。 python 2.x 中的 json.dumps() 操作json 作为一种广为各大平台所采用的数据交换格式，在 python 中更是被广泛使用，然而，在 python 2.x 中，有些地方需要注意。对于数据结构中的字符串类型为 str、 但实际上定义的是一个国际字符串的情况，json.dumps() 的结果如下：12345678# python 2.7&gt;&gt;&gt; a = &#123;'Natasha': '娜塔莎'&#125;&gt;&gt;&gt; a_json_1 = json.dumps(a)&gt;&gt;&gt; a_json_1'&#123;"Natasha": "\\u5a1c\\u5854\\u838e"&#125;'&gt;&gt;&gt; a_json_2 = json.dumps(a, ensure_ascii=False)&gt;&gt;&gt; a_json_2'&#123;"Natasha": "\xe5\xa8\x9c\xe5\xa1\x94\xe8\x8e\x8e"&#125;' 可以看到，在这种情形下，当 ensure_ascii 为 True 时，json.dumps() 操作返回值的类型为 str，其会将 a 中的中文字符映射为其对应的 unicode code point 的形式，但是却是以 ASCII 字符存储的（即 &#39;\\u5a1c&#39; 对应 6 个字符而非 1 个）；当 ensure_ascii 为 False 时，json.dumps() 操作的返回值类型仍然为 str，其会将中文字符映射为其对应的某种 unicode 编码（这里为 utf-8）后的字节串，所以我们将 a_json_2 译码就可以得到我们想要的 json：12345# python 2.7&gt;&gt;&gt; a_json_2.decode('utf-8')u'&#123;"Natasha": "\u5a1c\u5854\u838e"&#125;'&gt;&gt;&gt; print a_json_2.decode('utf-8')&#123;"Natasha": "娜塔莎"&#125; 对于数据结构中的字符串类型为 unicode 的情况，json.dumps() 的结果如下：12345678910# python 2.7&gt;&gt;&gt; u = &#123;u'Natasha': u'娜塔莎'&#125;&gt;&gt;&gt; u_json_1 = json.dumps(u)&gt;&gt;&gt; u_json_1'&#123;"Natasha": "\\u5a1c\\u5854\\u838e"&#125;'&gt;&gt;&gt; u_json_2 = json.dumps(u, ensure_ascii=False)&gt;&gt;&gt; u_json_2u'&#123;"Natasha": "\u5a1c\u5854\u838e"&#125;'&gt;&gt;&gt; print u_json_2&#123;"Natasha": "娜塔莎"&#125; 在这种情形下，当 ensure_ascii 为 True 时，json.dumps() 操作返回值的类型为 str，其得到的结果和前面对 a 操作返回的结果完全一样；而当ensure_ascii 为 False 时，json.dumps() 操作的返回值类型变为 unicode，原始数据结构中的中文字符在返回值中完整地保留了下来。对于数据结构中的字符串类型既有 unicode 又有 str 的情形，运用 json.dumps() 时将 ensure_ascii 设为 False 的情况又会完全不同。当数据结构中的 ASCII 字符串为 str 类型，国际字符串为 unicode 类型时（如 u = {&#39;Natasha&#39;: u&#39;娜塔莎&#39;}），json.dumps() 的返回值是正常的、符合预期的 unicode 字符串；当数据结构中有国际字符串为 str 类型，又存在其他字符串为 unicode 类型时（如 u = {u&#39;Natasha&#39;: &#39;娜塔莎&#39;} 或 u = {u&#39;娜塔莉娅&#39;: &#39;娜塔莎&#39;}），json.dumps() 会抛出异常 UnicodeDecodeError，这是因为系统会将数据结构中 str 类型字符串都转换为 unicode 类型，而系统的默认编译码方式为 ascii 编码，因而对 str 类型的国际字符串进行 ascii 译码就必然会出错。]]></content>
      <categories>
        <category>python学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>unicode</tag>
      </tags>
  </entry>
</search>
